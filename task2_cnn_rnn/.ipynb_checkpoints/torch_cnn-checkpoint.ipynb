{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c096ad27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:37:16.844272Z",
     "start_time": "2022-12-02T15:37:11.076000Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7269dabc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:37:17.067676Z",
     "start_time": "2022-12-02T15:37:16.910098Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 数据的导入与预处理\n",
    "train_data = pd.read_csv(\"sentiment-analysis-on-movie-reviews/train.tsv\",\n",
    "                         sep='\\t', encoding='ISO-8859-1')\n",
    "phrase_id = train_data.loc[:, 'PhraseId'].values\n",
    "phrase = train_data.loc[:, 'Phrase'].values\n",
    "sentiment = train_data.loc[:, 'Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a47cd29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:37:22.810321Z",
     "start_time": "2022-12-02T15:37:17.132501Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 由原始表格数据生成词典与词向量\n",
    "train_texts = [[word for word in sentence.lower().split()] for sentence in\n",
    "               phrase]  # lower()使大写变小写\n",
    "dictionary = corpora.Dictionary(train_texts)  # 词典的生成,可以根据列表或列表的列表\n",
    "# gensim中的dictionary实际上是一个单词到id的唯一映射,是一种词典,id从0开始计算\n",
    "corpus = [dictionary.doc2bow(text) for text in train_texts]  # 稀疏one-hot向量形式\n",
    "dict_len = len(dictionary)  # 词典中词的总数\n",
    "\n",
    "# 由稀疏的bow向量生成稠密的文本特征向量\n",
    "word_feature = np.zeros((dict_len, len(phrase)), dtype='uint8')  # unit8降低内存\n",
    "for i in range(len(corpus)):\n",
    "    for bow in corpus[i]:\n",
    "        word_feature[bow[0], i] = bow[1]\n",
    "\n",
    "# 情感标签特征向量的生成(one-hot形式)\n",
    "sentiment_vec = np.zeros((5, len(sentiment)))\n",
    "for i in range(len(sentiment)):\n",
    "    sentiment_vec[sentiment[i], i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357c270d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:37:25.034344Z",
     "start_time": "2022-12-02T15:37:25.020379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
      "  (conv2): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
      "  (conv3): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
      "  (conv4): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
      "  (fc1): Linear(in_features=1030, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv1d(1, 1, 5)\n",
    "        self.conv2 = nn.Conv1d(1, 1, 5)\n",
    "        self.conv3 = nn.Conv1d(1, 1, 5)\n",
    "        self.conv4 = nn.Conv1d(1, 1, 5)\n",
    "        self.fc1 = nn.Linear(1030, 100)\n",
    "        self.fc2 = nn.Linear(100, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling\n",
    "        x = F.max_pool1d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool1d(F.relu(self.conv2(x)), 2)\n",
    "        x = F.max_pool1d(F.relu(self.conv3(x)), 2)\n",
    "        x = F.max_pool1d(F.relu(self.conv4(x)), 2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41e8a5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:37:29.073544Z",
     "start_time": "2022-12-02T15:37:29.045617Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "torch.Size([1, 1, 5])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1, 5])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1, 5])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 1, 5])\n",
      "torch.Size([1])\n",
      "torch.Size([100, 1030])\n",
      "torch.Size([100])\n",
      "torch.Size([5, 100])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "for i in range(12):\n",
    "    print(params[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af88da65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:37:32.163282Z",
     "start_time": "2022-12-02T15:37:32.118402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 2.,  ..., 0., 0., 0.]])\n",
      "tensor([[0.2091, 0.1890, 0.2037, 0.2065, 0.1917]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZLTY\\AppData\\Local\\Temp\\ipykernel_28756\\1684638429.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))\n"
     ]
    }
   ],
   "source": [
    "input = torch.from_numpy(word_feature[:, 0].T,).reshape(1, 16540).float()\n",
    "print(input)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90da3bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:37:36.432865Z",
     "start_time": "2022-12-02T15:37:36.406936Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05a18776",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:46:12.271219Z",
     "start_time": "2022-12-02T15:46:11.476146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
       "  (conv3): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
       "  (conv4): Conv1d(1, 1, kernel_size=(5,), stride=(1,))\n",
       "  (fc1): Linear(in_features=1030, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba8787a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-02T15:58:42.044337Z",
     "start_time": "2022-12-02T15:48:51.028861Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZLTY\\AppData\\Local\\Temp\\ipykernel_28756\\1684638429.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc2(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2000 loss: 1.283\n",
      " 4000 loss: 1.339\n",
      " 6000 loss: 1.378\n",
      " 8000 loss: 1.366\n",
      "10000 loss: 1.353\n",
      "12000 loss: 1.376\n",
      "14000 loss: 1.359\n",
      "16000 loss: 1.360\n",
      "18000 loss: 1.341\n",
      "20000 loss: 1.358\n",
      "22000 loss: 1.368\n",
      "24000 loss: 1.369\n",
      "26000 loss: 1.356\n",
      "28000 loss: 1.354\n",
      "30000 loss: 1.375\n",
      "32000 loss: 1.407\n",
      "34000 loss: 1.422\n",
      "36000 loss: 1.403\n",
      "38000 loss: 1.429\n",
      "40000 loss: 1.405\n",
      "42000 loss: 1.382\n",
      "44000 loss: 1.391\n",
      "46000 loss: 1.414\n",
      "48000 loss: 1.423\n",
      "50000 loss: 1.371\n",
      "52000 loss: 1.409\n",
      "54000 loss: 1.402\n",
      "56000 loss: 1.387\n",
      "58000 loss: 1.389\n",
      "60000 loss: 1.421\n",
      "62000 loss: 1.383\n",
      "64000 loss: 1.417\n",
      "66000 loss: 1.384\n",
      "68000 loss: 1.382\n",
      "70000 loss: 1.387\n",
      "72000 loss: 1.405\n",
      "74000 loss: 1.454\n",
      "76000 loss: 1.409\n",
      "78000 loss: 1.415\n",
      "80000 loss: 1.398\n",
      "82000 loss: 1.373\n",
      "84000 loss: 1.411\n",
      "86000 loss: 1.377\n",
      "88000 loss: 1.394\n",
      "90000 loss: 1.421\n",
      "92000 loss: 1.415\n",
      "94000 loss: 1.402\n",
      "96000 loss: 1.430\n",
      "98000 loss: 1.398\n",
      "100000 loss: 1.389\n",
      "102000 loss: 1.416\n",
      "104000 loss: 1.389\n",
      "106000 loss: 1.367\n",
      "108000 loss: 1.422\n",
      "110000 loss: 1.406\n",
      "112000 loss: 1.411\n",
      "114000 loss: 1.399\n",
      "116000 loss: 1.414\n",
      "118000 loss: 1.417\n",
      "120000 loss: 1.405\n",
      "122000 loss: 1.438\n",
      "124000 loss: 1.361\n",
      "126000 loss: 1.423\n",
      "128000 loss: 1.415\n",
      "130000 loss: 1.380\n",
      "132000 loss: 1.413\n",
      "134000 loss: 1.411\n",
      "136000 loss: 1.400\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for epoch in range(3):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i in range(136060):\n",
    "        # get the inputs\n",
    "        inputs = torch.from_numpy(word_feature[:, i].T,).reshape(1, 16540).float()\n",
    "        labels = torch.from_numpy(sentiment_vec[:, i].T,).reshape(1, 5).float()\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10000 == 9999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 10000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print(f'cost time: {end-start} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 526.844,
   "position": {
    "height": "40px",
    "left": "78px",
    "right": "20px",
    "top": "12px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
